{"bert_config_file": "/home/sakus/ws/pytorch-pretrained-BERT/data/uncased_L-24_H-1024_A-16/bert_config.json", "vocab_file": "/home/sakus/ws/pytorch-pretrained-BERT/data/uncased_L-24_H-1024_A-16/vocab.txt", "output_dir": "final_output/coqa/shuffle_document_words/seed1", "task_name": "coqa", "dataset_option": null, "input_ablation": "shuffle_document_words", "cache_dir": "cache", "corenlp_cache_dir": "corenlp_{}", "data_dir": "/uge_mnt/home/sakus/data/coqa", "init_checkpoint": "final_output/coqa/trained/pytorch_model_fixed.bin", "do_lower_case": true, "max_seq_length": 384, "doc_stride": 128, "max_query_length": 64, "do_train": false, "do_eval": true, "do_test": false, "train_batch_size": 32, "eval_batch_size": 128, "learning_rate": 5e-05, "num_train_epochs": 3.0, "warmup_proportion": 0.1, "save_checkpoints_steps": 200, "loss_report_steps": 0, "eval_steps": 2000, "iterations_per_loop": 1000, "n_best_size": 20, "max_answer_length": 30, "verbose_logging": false, "no_cuda": false, "seed": 1, "gradient_accumulation_steps": 1, "local_rank": -1, "optimize_on_cpu": false, "fp16": true, "loss_scale": 128, "log_spec": null, "no_cache": true, "eval_on_train": false, "allow_impossible": false, "null_score_diff_threshold": 0.0}